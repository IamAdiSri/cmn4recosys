{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Collaborative Memory Network for Recommendation Systems\n",
    "**_Ebesu, Shen, Fang - The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval - SIGIR '18_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This](https://github.com/IamAdiSri/cmn4recosys) notebook by [**Aditya Srivastava**](https://github.com/IamAdiSri/) is a PyTorch port to the original TensorFlow [project](https://github.com/tebesu/CollaborativeMemoryNetwork)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:15:48.147829Z",
     "start_time": "2019-07-11T10:15:47.826072Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:15:49.080256Z",
     "start_time": "2019-07-11T10:15:48.691466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:15:49.495930Z",
     "start_time": "2019-07-11T10:15:49.487350Z"
    }
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    ssdir = 'snapshots/'\n",
    "    logdir = 'logs/'\n",
    "    dataset = 'data/citeulike-a.npz'\n",
    "    version = 'model_v2'\n",
    "    pretrain = 'pretrain/citeulike-a_e50_v2.npz' # output/input location for pretrained embeddings\n",
    "    embed_size = 50\n",
    "    pretraining_epochs = 15\n",
    "    pretraining_l2_lambda = 0.001 # l2 regularization for pretraining\n",
    "    epochs = 30 # training epochs (originally 30)\n",
    "    batch_size = 128\n",
    "    hops = 2 # number of hops/layers\n",
    "    training_l2_lambda = 0.1 # l2 regularization for training\n",
    "    neg_count = 4 # negative samples count\n",
    "    learning_rate = 0.001\n",
    "    decay_rate = 0.9\n",
    "    momentum = 0.9\n",
    "    grad_clip = 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:15:50.449285Z",
     "start_time": "2019-07-11T10:15:50.443726Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def truncated_normal_(tensor, mean=0, std=1):\n",
    "    size = tensor.shape\n",
    "    tmp = tensor.new_empty(size + (4,)).normal_()\n",
    "    valid = (tmp < 2) & (tmp > -2)\n",
    "    ind = valid.max(-1, keepdim=True)[1]\n",
    "    tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))\n",
    "    tensor.data.mul_(std).add_(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:15:51.609437Z",
     "start_time": "2019-07-11T10:15:51.568149Z"
    },
    "code_folding": [
     2,
     27,
     35,
     42,
     48,
     54,
     72,
     83
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Wraps dataset and produces batches for the model to consume\n",
    "\n",
    "        :param filename: path to training data for npz file\n",
    "        \"\"\"\n",
    "        self._data = np.load(filename, allow_pickle=True)\n",
    "        self.train_data = self._data['train_data'][:, :2]\n",
    "        self.test_data = self._data['test_data'].tolist()\n",
    "        self._train_index = np.arange(len(self.train_data), dtype=np.uint)\n",
    "        self._n_users, self._n_items = self.train_data.max(axis=0) + 1\n",
    "\n",
    "        # Neighborhoods\n",
    "        self.user_items = defaultdict(set)\n",
    "        self.item_users = defaultdict(set)\n",
    "        for u, i in self.train_data:\n",
    "            self.user_items[u].add(i)\n",
    "            self.item_users[i].add(u)\n",
    "        # Get a list version so we do not need to perform type casting\n",
    "        self.item_users_list = {k: list(v) for k, v in self.item_users.items()}\n",
    "        self._max_user_neighbors = max([len(x) for x in self.item_users.values()])\n",
    "        self.user_items = dict(self.user_items)\n",
    "        self.item_users = dict(self.item_users)\n",
    "\n",
    "    @property\n",
    "    def train_size(self):\n",
    "        \"\"\"\n",
    "        :return: number of examples in training set\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.train_data)\n",
    "\n",
    "    @property\n",
    "    def user_count(self):\n",
    "        \"\"\"\n",
    "        Number of users in dataset\n",
    "        \"\"\"\n",
    "        return self._n_users\n",
    "\n",
    "    @property\n",
    "    def item_count(self):\n",
    "        \"\"\"\n",
    "        Number of items in dataset\n",
    "        \"\"\"\n",
    "        return self._n_items\n",
    "\n",
    "    def _sample_item(self):\n",
    "        \"\"\"\n",
    "        Draw an item uniformly\n",
    "        \"\"\"\n",
    "        return np.random.randint(0, self.item_count)\n",
    "\n",
    "    def _sample_negative_item(self, user_id):\n",
    "        \"\"\"\n",
    "        Uniformly sample a negative item\n",
    "        \"\"\"\n",
    "        if user_id > self.user_count:\n",
    "            raise ValueError(\"Trying to sample user id: {} > user count: {}\".format(\n",
    "                user_id, self.user_count))\n",
    "\n",
    "        n = self._sample_item()\n",
    "        positive_items = self.user_items[user_id]\n",
    "\n",
    "        if len(positive_items) >= self.item_count:\n",
    "            raise ValueError(\"The User has rated more items than possible %s / %s\" % (\n",
    "                len(positive_items), self.item_count))\n",
    "        while n in positive_items or n not in self.item_users:\n",
    "            n = self._sample_item()\n",
    "        return n\n",
    "\n",
    "    def _generate_data(self, neg_count):\n",
    "        idx = 0\n",
    "        self._examples = np.zeros((self.train_size*neg_count, 3),\n",
    "                                  dtype=np.uint32)\n",
    "        self._examples[:, :] = 0\n",
    "        for user_idx, item_idx in self.train_data:\n",
    "            for _ in range(neg_count):\n",
    "                neg_item_idx = self._sample_negative_item(user_idx)\n",
    "                self._examples[idx, :] = [user_idx, item_idx, neg_item_idx]\n",
    "                idx += 1\n",
    "\n",
    "    def get_data(self, batch_size: int, neighborhood: bool, neg_count: int):\n",
    "        \"\"\"\n",
    "        Batch data together as (user, item, negative item), pos_neighborhood,\n",
    "        length of neighborhood, negative_neighborhood, length of negative neighborhood\n",
    "\n",
    "        if neighborhood is False returns only user, item, negative_item so we\n",
    "        can reuse this for non-neighborhood-based methods.\n",
    "\n",
    "        :param batch_size: size of the batch\n",
    "        :param neighborhood: return the neighborhood information or not\n",
    "        :param neg_count: number of negative samples to uniformly draw per a pos\n",
    "                          example\n",
    "        :return: generator\n",
    "        \"\"\"\n",
    "        # Allocate inputs\n",
    "        batch = np.zeros((batch_size, 3), dtype=np.uint32)\n",
    "        pos_neighbor = np.zeros((batch_size, self._max_user_neighbors), dtype=np.int32)\n",
    "        pos_length = np.zeros(batch_size, dtype=np.int32)\n",
    "        neg_neighbor = np.zeros((batch_size, self._max_user_neighbors), dtype=np.int32)\n",
    "        neg_length = np.zeros(batch_size, dtype=np.int32)\n",
    "\n",
    "        # Shuffle index\n",
    "        np.random.shuffle(self._train_index)\n",
    "\n",
    "        idx = 0\n",
    "        for user_idx, item_idx in self.train_data[self._train_index]:\n",
    "            # TODO: set positive values outside of for loop\n",
    "            for _ in range(neg_count):\n",
    "                neg_item_idx = self._sample_negative_item(user_idx)\n",
    "                batch[idx, :] = [user_idx, item_idx, neg_item_idx]\n",
    "\n",
    "                # Get neighborhood information\n",
    "                if neighborhood:\n",
    "                    if len(self.item_users.get(item_idx, [])) > 0:\n",
    "                        pos_length[idx] = len(self.item_users[item_idx])\n",
    "                        pos_neighbor[idx, :pos_length[idx]] = self.item_users_list[item_idx]\n",
    "                    else:\n",
    "                        # Length defaults to 1\n",
    "                        pos_length[idx] = 1\n",
    "                        pos_neighbor[idx, 0] = item_idx\n",
    "\n",
    "                    if len(self.item_users.get(neg_item_idx, [])) > 0:\n",
    "                        neg_length[idx] = len(self.item_users[neg_item_idx])\n",
    "                        neg_neighbor[idx, :neg_length[idx]] = self.item_users_list[neg_item_idx]\n",
    "                    else:\n",
    "                        # Length defaults to 1\n",
    "                        neg_length[idx] = 1\n",
    "                        neg_neighbor[idx, 0] = neg_item_idx\n",
    "\n",
    "                idx += 1\n",
    "                # Yield batch if we filled queue\n",
    "                if idx == batch_size:\n",
    "                    if neighborhood:\n",
    "                        max_length = max(neg_length.max(), pos_length.max())\n",
    "                        yield batch, pos_neighbor[:, :max_length], pos_length, \\\n",
    "                              neg_neighbor[:, :max_length], neg_length\n",
    "                        pos_length[:] = 1\n",
    "                        neg_length[:] = 1\n",
    "                    else:\n",
    "                        yield batch\n",
    "                    # Reset\n",
    "                    idx = 0\n",
    "\n",
    "        # Provide remainder\n",
    "        if idx > 0:\n",
    "            if neighborhood:\n",
    "                max_length = max(neg_length[:idx].max(), pos_length[:idx].max())\n",
    "                yield batch[:idx], pos_neighbor[:idx, :max_length], pos_length[:idx], \\\n",
    "                      neg_neighbor[:idx, :max_length], neg_length[:idx]\n",
    "            else:\n",
    "                yield batch[:idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:15:52.424482Z",
     "start_time": "2019-07-11T10:15:51.857606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16980 5551 311\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(config.dataset)\n",
    "\n",
    "config.item_count = dataset.item_count\n",
    "config.user_count = dataset.user_count\n",
    "config.max_neighbors = dataset._max_user_neighbors\n",
    "\n",
    "print(dataset.item_count, dataset.user_count, dataset._max_user_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "The loss function is common between both, pairwise GMF pretraining and CMN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:15:53.603884Z",
     "start_time": "2019-07-11T10:15:53.590815Z"
    },
    "code_folding": [
     1,
     4,
     13
    ]
   },
   "outputs": [],
   "source": [
    "class LossLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossLayer, self).__init__()\n",
    "\n",
    "    def forward(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: predicted value\n",
    "        :param y: ground truth\n",
    "        :returns: Loss\n",
    "        \"\"\"        \n",
    "        bprl = torch.squeeze(self.bpr_loss(X, y))        \n",
    "        return bprl\n",
    "    \n",
    "    def bpr_loss(self, positive, negative):\n",
    "        r\"\"\"\n",
    "        Pairwise Loss from Bayesian Personalized Ranking.\n",
    "\n",
    "        \\log \\sigma(pos - neg)\n",
    "\n",
    "        where \\sigma is the sigmoid function, we try to set the ranking\n",
    "\n",
    "        if pos > neg = + number\n",
    "        if neg < pos = - number\n",
    "\n",
    "        Then applying the sigmoid to obtain a monotonically increasing function. Any\n",
    "        monotonically increasing function could be used, eg piecewise or probit.\n",
    "\n",
    "        :param positive: Score of prefered example\n",
    "        :param negative: Score of negative example\n",
    "        :param name: str, name scope\n",
    "        :returns: mean loss\n",
    "        \"\"\"\n",
    "        difference = positive - negative\n",
    "        # Numerical stability\n",
    "        eps = 1e-12\n",
    "        loss = -1*torch.log(torch.sigmoid(difference) + eps)\n",
    "        return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pretraining User and Item Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:15:54.995647Z",
     "start_time": "2019-07-11T10:15:54.976591Z"
    },
    "code_folding": [
     2,
     24
    ]
   },
   "outputs": [],
   "source": [
    "class PairwiseGMF(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructs the user/item memories and user/item external memory/outputs\n",
    "\n",
    "        Also add the embedding lookups\n",
    "        \"\"\"\n",
    "        super(PairwiseGMF, self).__init__()\n",
    "        \n",
    "        # MemoryEmbed\n",
    "        self.user_memory = nn.Embedding(config.user_count, config.embed_size)\n",
    "        truncated_normal_(self.user_memory.weight, std=0.01)\n",
    "        self.user_memory.weight.requires_grad = True\n",
    "\n",
    "        # ItemMemory\n",
    "        self.item_memory = nn.Embedding(config.item_count, config.embed_size)        \n",
    "        truncated_normal_(self.item_memory.weight, std=0.01)\n",
    "        self.item_memory.weight.requires_grad = True\n",
    "        \n",
    "        self.v = nn.Linear(config.embed_size, 1, bias=False)\n",
    "        nn.init.xavier_uniform_(self.v.weight)\n",
    "        self.v.weight.requires_grad = True\n",
    "\n",
    "    def forward(self, input_users, input_items, input_items_negative):\n",
    "        \"\"\"\n",
    "        Construct the model; main part of it goes here\n",
    "        \"\"\"\n",
    "        # [batch, embedding size]\n",
    "        cur_user = self.user_memory(input_users)\n",
    "\n",
    "        # Item memories a query\n",
    "        cur_item = self.item_memory(input_items)\n",
    "        cur_item_negative = self.item_memory(input_items_negative)\n",
    "\n",
    "        score = F.relu(self.v(cur_user * cur_item))\n",
    "        negative_output = F.relu(self.v(cur_user * cur_item_negative))\n",
    "        \n",
    "        return score, negative_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:15:58.949832Z",
     "start_time": "2019-07-11T10:15:55.437873Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PairwiseGMF().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:16:01.398216Z",
     "start_time": "2019-07-11T10:16:01.390230Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_memory.weight\n",
      "item_memory.weight\n",
      "v.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:30:10.543260Z",
     "start_time": "2019-07-11T10:16:05.206619Z"
    },
    "code_folding": [
     11
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8648781f2d4bbf9a8a1860b73edb72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: Avg Loss/Batch 0.693170            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a00c4cc9236433395c13ebb391125aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Avg Loss/Batch 0.693148            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6837ecb46194c5bb015ece95a351203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: Avg Loss/Batch 0.693148            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703c78b5e412481ca217d6b3188fcba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: Avg Loss/Batch 0.693138            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a034fe1500743eaa95382d92ea2462b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: Avg Loss/Batch 0.682225            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14051d7fe9b4af4ace6d6c2835adc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: Avg Loss/Batch 0.517125            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18e1516deca42ae8fe9494260eb5ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: Avg Loss/Batch 0.244349            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f6f7a63ffe4ea2afb57530c59c2165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: Avg Loss/Batch 0.137857            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ea90a6e15f4418b72734723327a133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: Avg Loss/Batch 0.099885            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc809f5019c0409f966c64e32db83ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: Avg Loss/Batch 0.080794            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80179341150442c9434d6d1cd529ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: Avg Loss/Batch 0.068308            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e5bc1c8ea94993815b2921c5e2e513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: Avg Loss/Batch 0.059544            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa806ce67faa47e7a324bba2b726ed8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: Avg Loss/Batch 0.053044            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429153818d1f454f94847da0205ae5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: Avg Loss/Batch 0.047668            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73acc47a667242adb41b20412321c4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: Avg Loss/Batch 0.043235            \n"
     ]
    }
   ],
   "source": [
    "criterion = LossLayer()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=config.learning_rate)\n",
    "\n",
    "for i in range(config.pretraining_epochs):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    progress = tqdm(enumerate(dataset.get_data(config.batch_size, False, config.neg_count)),\n",
    "                    dynamic_ncols=True, total=(dataset.train_size * config.neg_count) // config.batch_size)\n",
    "    loss = []\n",
    "    for k, batch in progress:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_users = torch.LongTensor(np.array(batch[:, 0], dtype=np.int32)).to(device)\n",
    "        input_items = torch.LongTensor(np.array(batch[:, 1], dtype=np.int32)).to(device)\n",
    "        input_items_negative = torch.LongTensor(np.array(batch[:, 2], dtype=np.int32)).to(device)\n",
    "        \n",
    "        score, negative_output = model(input_users, input_items, input_items_negative)\n",
    "        batch_loss = criterion(score, negative_output)\n",
    "        \n",
    "        # adding l2 regularisation\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in ['v.weight']:\n",
    "                l2 = torch.sqrt(param.pow(2).sum())\n",
    "                batch_loss += (config.pretraining_l2_lambda * l2)\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss.append(batch_loss.item())\n",
    "        progress.set_description(u\"[{}] Loss: {:,.4f} » » » » \".format(i, batch_loss.item()))\n",
    "\n",
    "    print(\"Epoch {}: Avg Loss/Batch {:<20,.6f}\".format(i, np.mean(loss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:30:10.948943Z",
     "start_time": "2019-07-11T10:30:10.859056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving embeddings to: pretrain/citeulike-a_e50_v2.npz\n"
     ]
    }
   ],
   "source": [
    "print('Saving embeddings to: %s' % config.pretrain)\n",
    "user_embed, item_embed, v = (model.user_memory.weight.detach().cpu(), model.item_memory.weight.detach().cpu(), model.v.weight.detach().cpu())\n",
    "np.savez(config.pretrain, user=user_embed, item=item_embed, v=v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Training CMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:30:11.314158Z",
     "start_time": "2019-07-11T10:30:11.287360Z"
    },
    "code_folding": [
     1,
     16,
     53,
     112
    ]
   },
   "outputs": [],
   "source": [
    "class VariableLengthMemoryLayer(nn.Module):\n",
    "    def __init__(self, hops, embed_size):\n",
    "        super(VariableLengthMemoryLayer, self).__init__()\n",
    "        \n",
    "        self.hops = hops\n",
    "        self.embed_size = embed_size\n",
    "        \n",
    "        self.hop_mapping = {}\n",
    "        for h in range(hops-1):\n",
    "            self.hop_mapping[str(h+1)] = nn.Linear(self.embed_size, self.embed_size, bias=True).to(device)\n",
    "            self.hop_mapping[str(h+1)].weight.requires_grad = True\n",
    "            self.hop_mapping[str(h+1)].bias.requires_grad = True\n",
    "            nn.init.kaiming_normal_(self.hop_mapping[str(h+1)].weight)\n",
    "            self.hop_mapping[str(h+1)].bias.data.fill_(1.0)    \n",
    "        self.hop_mapping = nn.ModuleDict(self.hop_mapping)\n",
    "    \n",
    "    def mask_mod(self, inputs, mask_length, maxlen=None):\n",
    "        \"\"\"\n",
    "        Apply a memory mask such that the values we mask result in being the\n",
    "        minimum possible value we can represent with a float32.\n",
    "\n",
    "        :param inputs: [batch size, length], dtype=tf.float32\n",
    "        :param memory_mask: [batch_size] shape Tensor of ints indicating the\n",
    "            length of inputs\n",
    "        :param maxlen: Sets the maximum length of the sequence; if None infered\n",
    "            from inputs\n",
    "        :returns: [batch size, length] dim Tensor with the mask applied\n",
    "        \"\"\"\n",
    "        # [batch_size, length] => Sequence Mask\n",
    "        memory_mask = torch.arange(maxlen).to(device).expand(len(mask_length), maxlen) < mask_length.unsqueeze(1)\n",
    "        memory_mask = memory_mask.float()\n",
    "\n",
    "        num_remaining_memory_slots = torch.sum(memory_mask, 1)\n",
    "\n",
    "        # Get the numerical limits of a float\n",
    "        finfo = np.finfo(np.float32)\n",
    "        # print(finfo)\n",
    "\n",
    "        # If True = 1 = Keep that memory slot\n",
    "        kept_indices = memory_mask\n",
    "\n",
    "        # Inverse\n",
    "        ignored_indices = memory_mask < 1\n",
    "        ignored_indices = ignored_indices.float()\n",
    "\n",
    "        # If we keep the indices its the max float value else its the\n",
    "        # minimum float value. Then we can take the minimum\n",
    "        lower_bound = finfo.max * kept_indices + finfo.min * ignored_indices\n",
    "        slice_length = torch.max(mask_length)\n",
    "        \n",
    "        # Return the elementwise\n",
    "        return torch.min(inputs[:, :slice_length], lower_bound[:, :slice_length])\n",
    "        \n",
    "    def apply_attention_memory(self, memory, output_memory, query, memory_mask=None, maxlen=None):\n",
    "        \"\"\"\n",
    "            :param memory: [batch size, max length, embedding size],\n",
    "                typically Matrix M\n",
    "            :param output_memory: [batch size, max length, embedding size],\n",
    "                typically Matrix C\n",
    "            :param query: [batch size, embed size], typically u\n",
    "            :param memory_mask: [batch size] dim Tensor, the length of each\n",
    "                sequence if variable length\n",
    "            :param maxlen: int/Tensor, the maximum sequence padding length; if None it\n",
    "                infers based on the max of memory_mask\n",
    "            :returns: AttentionOutput\n",
    "                 output: [batch size, embedding size]\n",
    "                 weight: [batch size, max length], the attention weights applied to\n",
    "                         the output representation.\n",
    "        \"\"\"\n",
    "        # query = [batch size, embeddings] => expand => [batch size, embeddings, 1]\n",
    "        # transpose => [batch size, 1, embeddings]\n",
    "        query_expanded = query.unsqueeze(-1).transpose(2, 1)\n",
    "\n",
    "        # Apply batched dot product\n",
    "        # memory = [batch size, <Max Length>, Embeddings]\n",
    "        # Broadcast the same memory across each dimension of max length\n",
    "        # We obtain an attention value for each memory,\n",
    "        # ie a_0 p_0, a_1 p_1, .. a_n p_n, which equates to the max length\n",
    "        #    because our query is only 1 dim, we only get attention over memory\n",
    "        #    for that query. If our query was 2-d then we would obtain a matrix.\n",
    "        # Return: [batch size, max length]\n",
    "        batched_dot_prod = query_expanded * memory\n",
    "        scores = batched_dot_prod.sum(2)\n",
    "\n",
    "        if memory_mask is not None:\n",
    "            scores = self.mask_mod(scores, memory_mask, maxlen)\n",
    "\n",
    "        # Attention over memories: [Batch Size, <Max Length>]\n",
    "        # equation 2\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # [Batch Size, <Max Length>] => [Batch Size, 1, <Max Length>]\n",
    "        probs_temp = attention.unsqueeze(1)\n",
    "\n",
    "        # Output_Memories = [batch size, <Max Length>, Embeddings]\n",
    "        # Transpose = [Batch Size, Embedding Size, <Max Length>]\n",
    "        c_temp = output_memory.transpose(2, 1)\n",
    "\n",
    "        # Apply a weighted scalar or attention to the external memory \n",
    "        # to get weighted neighborhood\n",
    "        # [batch size, 1, <max length>] * [batch size, embedding size, <max length>]\n",
    "        neighborhood = c_temp * probs_temp\n",
    "\n",
    "        # Sum the weighted memories together\n",
    "        # Input:  [batch Size, embedding size, <max length>]\n",
    "        # Output: [Batch Size, Embedding Size]\n",
    "        # Weighted output vector\n",
    "        # equation 3\n",
    "        weighted_output = neighborhood.sum(2)\n",
    "\n",
    "        return {'weight':attention, 'output':weighted_output}\n",
    "    \n",
    "    def forward(self, query, memory, output_memory, seq_length, maxlen=32):\n",
    "        # find maximum length of sequences in this batch\n",
    "        cur_max = torch.max(seq_length).item()\n",
    "        # slice to max length\n",
    "        memory = memory[:, :cur_max]\n",
    "        output_memory = output_memory[:, :cur_max]\n",
    "        \n",
    "        user_query, item_query = query\n",
    "        hop_outputs = []\n",
    "        \n",
    "        # hop 0\n",
    "        # z = m_u + e_i\n",
    "        z = user_query + item_query\n",
    "        \n",
    "        for hop_k in range(self.hops):\n",
    "            # hop 1, ... , hop self.hops-1\n",
    "            if hop_k != 0:                \n",
    "                # f(Wz + o + b)\n",
    "                # equation 6\n",
    "                z = F.relu(self.hop_mapping[str(hop_k)](z) + memory_hop['output'])\n",
    "            \n",
    "            # apply attention\n",
    "            memory_hop = self.apply_attention_memory(memory, \n",
    "                                               output_memory,\n",
    "                                               z, \n",
    "                                               seq_length, \n",
    "                                               maxlen)\n",
    "            hop_outputs.append(memory_hop)\n",
    "        \n",
    "        return hop_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:30:11.660886Z",
     "start_time": "2019-07-11T10:30:11.652859Z"
    },
    "code_folding": [
     2,
     17
    ]
   },
   "outputs": [],
   "source": [
    "class OutputModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_size):\n",
    "        super(OutputModule, self).__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        \n",
    "        self.dense = nn.Linear(self.embed_size*2, self.embed_size, bias=True)\n",
    "        self.dense.weight.requires_grad = True\n",
    "        self.dense.bias.requires_grad = True\n",
    "        nn.init.kaiming_normal_(self.dense.weight)\n",
    "        self.dense.bias.data.fill_(1.0)\n",
    "        \n",
    "        self.out = nn.Linear(self.embed_size, 1, bias = False)\n",
    "        self.out.weight.requires_grad = True\n",
    "        nn.init.xavier_uniform_(self.out.weight)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        output = F.relu(self.dense(inputs))\n",
    "        output = self.out(output)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:30:11.996615Z",
     "start_time": "2019-07-11T10:30:11.984344Z"
    },
    "code_folding": [
     2,
     25
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CollaborativeMemoryNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, user_embeddings, item_embeddings):\n",
    "        super(CollaborativeMemoryNetwork, self).__init__()\n",
    "\n",
    "        # MemoryEmbed\n",
    "        self.user_memory = nn.Embedding(user_embeddings.shape[0], user_embeddings.shape[1])\n",
    "        self.user_memory.weight = nn.Parameter(torch.from_numpy(user_embeddings))\n",
    "        self.user_memory.weight.requires_grad = True\n",
    "        \n",
    "        # ItemMemory\n",
    "        self.item_memory = nn.Embedding(item_embeddings.shape[0], item_embeddings.shape[1])\n",
    "        self.item_memory.weight = nn.Parameter(torch.from_numpy(item_embeddings))\n",
    "        self.item_memory.weight.requires_grad = True\n",
    "\n",
    "        # MemoryOutput\n",
    "        self.user_output = nn.Embedding(user_embeddings.shape[0], user_embeddings.shape[1])\n",
    "        truncated_normal_(self.user_output.weight, std=0.01)\n",
    "        self.user_output.weight.requires_grad = True\n",
    "\n",
    "        self.mem_layer = VariableLengthMemoryLayer(2, config.embed_size)\n",
    "\n",
    "        self.output_module = OutputModule(config.embed_size)\n",
    "\n",
    "    \n",
    "    def forward(self, input_users, input_items, input_items_negative, \n",
    "                input_neighborhoods, input_neighborhood_lengths, \n",
    "                input_neighborhoods_negative, input_neighborhood_lengths_negative, evaluation=False):\n",
    "        \n",
    "        # get embeddings from user memory\n",
    "        cur_user = self.user_memory(input_users)\n",
    "        cur_user_output = self.user_output(input_users)\n",
    "\n",
    "        # get embeddings from item memory\n",
    "        cur_item = self.item_memory(input_items)\n",
    "        \n",
    "        # queries\n",
    "        query = (cur_user, cur_item)\n",
    "        \n",
    "        # positive\n",
    "        neighbor = self.mem_layer(query, \n",
    "                                  self.user_memory(input_neighborhoods), \n",
    "                                  self.user_output(input_neighborhoods), \n",
    "                                  input_neighborhood_lengths, \n",
    "                                  config.max_neighbors)[-1]['output']\n",
    "        \n",
    "        score = self.output_module(torch.cat((cur_user * cur_item, neighbor), 1))\n",
    "        \n",
    "        \n",
    "        if evaluation:\n",
    "            return score\n",
    "        \n",
    "        cur_item_negative = self.item_memory(input_items_negative)\n",
    "        neg_query = (cur_user, cur_item_negative)\n",
    "            \n",
    "        # negative\n",
    "        neighbor_negative = self.mem_layer(neg_query, \n",
    "                                           self.user_memory(input_neighborhoods_negative), \n",
    "                                           self.user_output(input_neighborhoods_negative), \n",
    "                                           input_neighborhood_lengths_negative, \n",
    "                                           config.max_neighbors)[-1]['output']\n",
    "        \n",
    "        negative_output = self.output_module(torch.cat((cur_user * cur_item_negative, \n",
    "                                                        neighbor_negative), 1))\n",
    "        \n",
    "        return score, negative_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:30:12.436720Z",
     "start_time": "2019-07-11T10:30:12.261206Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# loading pretrained embeddings\n",
    "embeddings = np.load(config.pretrain, allow_pickle=True)\n",
    "\n",
    "# initialize model\n",
    "model = CollaborativeMemoryNetwork(embeddings['user']*0.5, embeddings['item']*0.5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:30:12.716889Z",
     "start_time": "2019-07-11T10:30:12.699395Z"
    },
    "code_folding": [
     0,
     41,
     56
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def get_model_scores(test_data, neighborhood, max_neighbors, return_scores=False):\n",
    "    \"\"\"\n",
    "    test_data = dict([positive, np.array[negatives]])\n",
    "    \"\"\"\n",
    "    out = ''\n",
    "    scores = []\n",
    "    progress = tqdm(test_data.items(), total=len(test_data),\n",
    "                    leave=False, desc=u'Evaluate || ')\n",
    "    for user, (pos, neg) in progress:\n",
    "        item_indices = list(neg) + [pos]\n",
    "\n",
    "        input_users = torch.LongTensor([user] * (len(neg) + 1)).to(device)\n",
    "        input_items = torch.LongTensor(item_indices).to(device)\n",
    "\n",
    "        if neighborhood is not None:\n",
    "            neighborhoods, neighborhood_length = (np.zeros((len(neg) + 1, max_neighbors), dtype=np.int32), \n",
    "                                                  np.ones(len(neg) + 1, dtype=np.int32))\n",
    "\n",
    "            for _idx, item in enumerate(item_indices):\n",
    "                _len = min(len(neighborhood.get(item, [])), max_neighbors)\n",
    "                if _len > 0:\n",
    "                    neighborhoods[_idx, :_len] = neighborhood[item][:_len]\n",
    "                    neighborhood_length[_idx] = _len\n",
    "                else:\n",
    "                    neighborhoods[_idx, :1] = user\n",
    "                    \n",
    "            input_neighborhoods = torch.LongTensor(neighborhoods).to(device)\n",
    "            input_neighborhood_lengths = torch.LongTensor(neighborhood_length).to(device)\n",
    "\n",
    "        score = model(input_users, input_items, None, input_neighborhoods, \n",
    "                      input_neighborhood_lengths, None, None, evaluation=True).cpu()\n",
    "        \n",
    "        scores.append(score.detach().numpy().ravel())\n",
    "        if return_scores:\n",
    "            s = ' '.join([\"{}:{}\".format(n, s) for s, n in zip(score.detach().numpy().ravel().tolist(), item_indices)])\n",
    "            out += \"{}\\t{}\\n\".format(user, s)\n",
    "    if return_scores:\n",
    "        return scores, out\n",
    "    return scores\n",
    "\n",
    "\n",
    "def evaluate_model(test_data, neighborhood, max_neighbors, EVAL_AT=[1, 5, 10]):\n",
    "    scores = get_model_scores(test_data, neighborhood, max_neighbors)\n",
    "    hrs = []\n",
    "    ndcgs = []\n",
    "    s = '\\n'\n",
    "    for k in EVAL_AT:\n",
    "        hr, ndcg = get_eval(scores, len(scores[0]) - 1, k)\n",
    "        s += \"{:<14} {:<14.6f}{:<14} {:.6f}\\n\".format('HR@%s' % k, hr, 'NDCG@%s' % k, ndcg)\n",
    "        hrs.append(hr)\n",
    "        ndcgs.append(ndcg)\n",
    "    print(s + '\\n')\n",
    "\n",
    "    return hrs, ndcgs\n",
    "\n",
    "\n",
    "def get_eval(scores, index, top_n=10):\n",
    "    \"\"\"\n",
    "    if the last element is the correct one, then\n",
    "    index = len(scores[0])-1\n",
    "    \"\"\"\n",
    "    ndcg = 0.0\n",
    "    hr = 0.0\n",
    "    assert len(scores[0]) > index and index >= 0\n",
    "\n",
    "    for score in scores:\n",
    "        # Get the top n indices\n",
    "        arg_index = np.argsort(-score)[:top_n]\n",
    "        if index in arg_index:\n",
    "            # Get the position\n",
    "            ndcg += np.log(2.0) / np.log(arg_index.tolist().index(index) + 2.0)\n",
    "            # Increment\n",
    "            hr += 1.0\n",
    "\n",
    "    return hr / len(scores), ndcg / len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:30:12.988867Z",
     "start_time": "2019-07-11T10:30:12.985085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_memory.weight\n",
      "item_memory.weight\n",
      "user_output.weight\n",
      "mem_layer.hop_mapping.1.weight\n",
      "mem_layer.hop_mapping.1.bias\n",
      "output_module.dense.weight\n",
      "output_module.dense.bias\n",
      "output_module.out.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:26:56.284224Z",
     "start_time": "2019-07-11T10:30:13.258655Z"
    },
    "code_folding": [
     21
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 0] [LR: 0.0008100000000000001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4537837ad540c98abc6ef9649eb023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: Avg Loss/Batch 0.536484            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.304450      NDCG@1         0.304450\n",
      "HR@5           0.638984      NDCG@5         0.480291\n",
      "HR@10          0.776257      NDCG@10        0.524932\n",
      "\n",
      "\n",
      "[Epoch: 1] [LR: 0.000729]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6059fb2febe4049a60cf3a35fb7038c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Avg Loss/Batch 0.422990            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.336876      NDCG@1         0.336876\n",
      "HR@5           0.697712      NDCG@5         0.527333\n",
      "HR@10          0.824536      NDCG@10        0.568500\n",
      "\n",
      "\n",
      "[Epoch: 2] [LR: 0.0006561000000000001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318bf4766c594417be3c0c0e01879979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: Avg Loss/Batch 0.363152            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.348946      NDCG@1         0.348946\n",
      "HR@5           0.709602      NDCG@5         0.539700\n",
      "HR@10          0.838768      NDCG@10        0.581711\n",
      "\n",
      "\n",
      "[Epoch: 3] [LR: 0.00059049]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea21e2e2d377499b9e96b00dd3c6b0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: Avg Loss/Batch 0.324254            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.354170      NDCG@1         0.354170\n",
      "HR@5           0.718249      NDCG@5         0.547642\n",
      "HR@10          0.839849      NDCG@10        0.587239\n",
      "\n",
      "\n",
      "[Epoch: 4] [LR: 0.000531441]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5982e59d764084a50929829a53b9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: Avg Loss/Batch 0.296596            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.361917      NDCG@1         0.361917\n",
      "HR@5           0.713385      NDCG@5         0.548750\n",
      "HR@10          0.843812      NDCG@10        0.591349\n",
      "\n",
      "\n",
      "[Epoch: 5] [LR: 0.0004782969]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e8d624e2564ddd8ca1e4218b6d514b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: Avg Loss/Batch 0.275701            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.367862      NDCG@1         0.367862\n",
      "HR@5           0.742569      NDCG@5         0.567055\n",
      "HR@10          0.862007      NDCG@10        0.605902\n",
      "\n",
      "\n",
      "[Epoch: 6] [LR: 0.00043046721]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012b87f9b07e413a9d73f81194d96214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: Avg Loss/Batch 0.258946            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.368402      NDCG@1         0.368402\n",
      "HR@5           0.740407      NDCG@5         0.565543\n",
      "HR@10          0.857323      NDCG@10        0.603527\n",
      "\n",
      "\n",
      "[Epoch: 7] [LR: 0.000387420489]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758c0d59cb994faca1c6067a1e63c691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: Avg Loss/Batch 0.245210            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.377409      NDCG@1         0.377409\n",
      "HR@5           0.750315      NDCG@5         0.575086\n",
      "HR@10          0.862007      NDCG@10        0.611604\n",
      "\n",
      "\n",
      "[Epoch: 8] [LR: 0.0003486784401]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094715b284de4e8d90ca44f13e5af77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: Avg Loss/Batch 0.233615            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.381553      NDCG@1         0.381553\n",
      "HR@5           0.749054      NDCG@5         0.576298\n",
      "HR@10          0.863808      NDCG@10        0.613759\n",
      "\n",
      "\n",
      "[Epoch: 9] [LR: 0.00031381059609000004]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af7a4f4583543289cf8d082fdf3bbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: Avg Loss/Batch 0.223697            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.365340      NDCG@1         0.365340\n",
      "HR@5           0.728878      NDCG@5         0.559591\n",
      "HR@10          0.853540      NDCG@10        0.600536\n",
      "\n",
      "\n",
      "[Epoch: 10] [LR: 0.00028242953648100003]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32979cb571b944b990ebb6501be57e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: Avg Loss/Batch 0.215119            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.386237      NDCG@1         0.386237\n",
      "HR@5           0.752297      NDCG@5         0.581444\n",
      "HR@10          0.870654      NDCG@10        0.620073\n",
      "\n",
      "\n",
      "[Epoch: 11] [LR: 0.00025418658283290005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd8f6111d5742fc92c824963e9bb700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: Avg Loss/Batch 0.207548            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.389479      NDCG@1         0.389479\n",
      "HR@5           0.754819      NDCG@5         0.583843\n",
      "HR@10          0.874077      NDCG@10        0.622627\n",
      "\n",
      "\n",
      "[Epoch: 12] [LR: 0.00022876792454961005]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b726169ad1f4f47ad3a7ac93e4e4e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: Avg Loss/Batch 0.200885            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.387678      NDCG@1         0.387678\n",
      "HR@5           0.759142      NDCG@5         0.585451\n",
      "HR@10          0.875518      NDCG@10        0.623158\n",
      "\n",
      "\n",
      "[Epoch: 13] [LR: 0.00020589113209464906]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5592da3548c548a5a22938798428bd3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: Avg Loss/Batch 0.194852            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.394524      NDCG@1         0.394524\n",
      "HR@5           0.762926      NDCG@5         0.590503\n",
      "HR@10          0.876419      NDCG@10        0.627431\n",
      "\n",
      "\n",
      "[Epoch: 14] [LR: 0.00018530201888518417]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1af5d7d1c2478cadc5d556f8dfc959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: Avg Loss/Batch 0.189326            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.393443      NDCG@1         0.393443\n",
      "HR@5           0.762565      NDCG@5         0.590215\n",
      "HR@10          0.874617      NDCG@10        0.626840\n",
      "\n",
      "\n",
      "[Epoch: 15] [LR: 0.00016677181699666576]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b974e6776a4dc686c30301f96b117a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: Avg Loss/Batch 0.184343            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.389479      NDCG@1         0.389479\n",
      "HR@5           0.767069      NDCG@5         0.590476\n",
      "HR@10          0.878040      NDCG@10        0.626466\n",
      "\n",
      "\n",
      "[Epoch: 16] [LR: 0.0001500946352969992]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c419acbd654915af40f96387d914d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: Avg Loss/Batch 0.179814            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.384976      NDCG@1         0.384976\n",
      "HR@5           0.758962      NDCG@5         0.584064\n",
      "HR@10          0.873176      NDCG@10        0.621357\n",
      "\n",
      "\n",
      "[Epoch: 17] [LR: 0.0001350851717672993]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496ed5c8fbe74669ae159a12f7d2b246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: Avg Loss/Batch 0.175646            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.382634      NDCG@1         0.382634\n",
      "HR@5           0.757881      NDCG@5         0.583172\n",
      "HR@10          0.873176      NDCG@10        0.620791\n",
      "\n",
      "\n",
      "[Epoch: 18] [LR: 0.00012157665459056936]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab4933b34cd4ab5a64864dfa506883c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: Avg Loss/Batch 0.171798            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.397946      NDCG@1         0.397946\n",
      "HR@5           0.768330      NDCG@5         0.595030\n",
      "HR@10          0.879661      NDCG@10        0.631262\n",
      "\n",
      "\n",
      "[Epoch: 19] [LR: 0.00010941898913151243]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2de17105104e0f98990c2b16ca5a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: Avg Loss/Batch 0.168240            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.390921      NDCG@1         0.390921\n",
      "HR@5           0.764907      NDCG@5         0.589925\n",
      "HR@10          0.876959      NDCG@10        0.626519\n",
      "\n",
      "\n",
      "[Epoch: 20] [LR: 9.847709021836118e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdafe20fb07647ada48b8ac5b77759eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: Avg Loss/Batch 0.164955            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.384255      NDCG@1         0.384255\n",
      "HR@5           0.755900      NDCG@5         0.582501\n",
      "HR@10          0.871735      NDCG@10        0.620442\n",
      "\n",
      "\n",
      "[Epoch: 21] [LR: 8.862938119652506e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320ac0bdaf134532887c28fe8e872722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: Avg Loss/Batch 0.161907            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.398126      NDCG@1         0.398126\n",
      "HR@5           0.766709      NDCG@5         0.593961\n",
      "HR@10          0.877860      NDCG@10        0.630421\n",
      "\n",
      "\n",
      "[Epoch: 22] [LR: 7.976644307687256e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b3691fda934fa592868e003c594571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: Avg Loss/Batch 0.159058            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.396685      NDCG@1         0.396685\n",
      "HR@5           0.764907      NDCG@5         0.592226\n",
      "HR@10          0.878580      NDCG@10        0.629335\n",
      "\n",
      "\n",
      "[Epoch: 23] [LR: 7.17897987691853e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74539283aa24cc884f236bd57802a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: Avg Loss/Batch 0.156400            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.386957      NDCG@1         0.386957\n",
      "HR@5           0.763106      NDCG@5         0.587451\n",
      "HR@10          0.876419      NDCG@10        0.624552\n",
      "\n",
      "\n",
      "[Epoch: 24] [LR: 6.461081889226677e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e962389a944482953a2b816acc2b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: Avg Loss/Batch 0.153930            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.397946      NDCG@1         0.397946\n",
      "HR@5           0.769411      NDCG@5         0.595003\n",
      "HR@10          0.880202      NDCG@10        0.631079\n",
      "\n",
      "\n",
      "[Epoch: 25] [LR: 5.81497370030401e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d690b7f4e3ee4fb99153553863c6ba9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: Avg Loss/Batch 0.151596            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.398667      NDCG@1         0.398667\n",
      "HR@5           0.769771      NDCG@5         0.596117\n",
      "HR@10          0.877319      NDCG@10        0.631399\n",
      "\n",
      "\n",
      "[Epoch: 26] [LR: 5.233476330273609e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c0d975aa894440b10f435c88b47e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: Avg Loss/Batch 0.149401            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.398487      NDCG@1         0.398487\n",
      "HR@5           0.768150      NDCG@5         0.595113\n",
      "HR@10          0.878941      NDCG@10        0.631363\n",
      "\n",
      "\n",
      "[Epoch: 27] [LR: 4.7101286972462485e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3b4f73b0214650af574d276f053772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27: Avg Loss/Batch 0.147341            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.396865      NDCG@1         0.396865\n",
      "HR@5           0.771933      NDCG@5         0.596800\n",
      "HR@10          0.879121      NDCG@10        0.631736\n",
      "\n",
      "\n",
      "[Epoch: 28] [LR: 4.239115827521624e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687b3a47f17c42bcbbb35f794a18a908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: Avg Loss/Batch 0.145400            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.397226      NDCG@1         0.397226\n",
      "HR@5           0.765448      NDCG@5         0.592837\n",
      "HR@10          0.879481      NDCG@10        0.630157\n",
      "\n",
      "\n",
      "[Epoch: 29] [LR: 3.8152042447694614e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf873d04b27541b891d755dbcd326d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=6232), HTML(value='')), layout=Layout(display…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: Avg Loss/Batch 0.143573            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate || ', max=5551, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HR@1           0.397406      NDCG@1         0.397406\n",
      "HR@5           0.767790      NDCG@5         0.594351\n",
      "HR@10          0.880022      NDCG@10        0.631091\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%capture training_loop_output\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=config.learning_rate, \n",
    "                                momentum=config.momentum)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=config.decay_rate)\n",
    "\n",
    "criterion = LossLayer()\n",
    "\n",
    "loss = []\n",
    "for i in range(config.epochs):    \n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Decay Learning Rate\n",
    "    scheduler.step()\n",
    "    # Print Learning Rate\n",
    "    print(\"[Epoch: {}] [LR: {}]\".format(i, scheduler.get_lr()[0]))\n",
    "    \n",
    "    progress = tqdm(enumerate(dataset.get_data(config.batch_size, True, config.neg_count)), \n",
    "                    dynamic_ncols=True, total=(dataset.train_size * config.neg_count) // config.batch_size)\n",
    "    \n",
    "    for k, batch in progress:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ratings, pos_neighborhoods, pos_neighborhood_length, neg_neighborhoods, neg_neighborhood_length = batch\n",
    "        \n",
    "        input_users = torch.LongTensor(np.array(ratings[:, 0], dtype=np.int32)).to(device)\n",
    "        input_items = torch.LongTensor(np.array(ratings[:, 1], dtype=np.int32)).to(device)\n",
    "        input_items_negative = torch.LongTensor(np.array(ratings[:, 2], dtype=np.int32)).to(device)\n",
    "        input_neighborhoods = torch.LongTensor(np.array(pos_neighborhoods, dtype=np.int32)).to(device)\n",
    "        input_neighborhood_lengths = torch.LongTensor(np.array(pos_neighborhood_length, dtype=np.int32)).to(device)\n",
    "        input_neighborhoods_negative = torch.LongTensor(np.array(neg_neighborhoods, dtype=np.int32)).to(device)\n",
    "        input_neighborhood_lengths_negative = torch.LongTensor(np.array(neg_neighborhood_length, dtype=np.int32)).to(device)\n",
    "        \n",
    "        score_pos, score_neg = model(input_users, input_items, input_items_negative, \n",
    "                                     input_neighborhoods, input_neighborhood_lengths, \n",
    "                                     input_neighborhoods_negative, input_neighborhood_lengths_negative)\n",
    "        \n",
    "        batch_loss = criterion(score_pos, score_neg)\n",
    "        \n",
    "        # adding l2 regularisation\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in ['mem_layer.hop_mapping.1.weight', \n",
    "                        'output_module.dense.weight', \n",
    "                        'output_module.out.weight']:\n",
    "                l2 = torch.sqrt(param.pow(2).sum())\n",
    "                batch_loss += (config.training_l2_lambda * l2)\n",
    "\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss.append(batch_loss.item())\n",
    "        progress.set_description(u\"[{}] Loss: {:,.4f} » » » » \".format(i, batch_loss.item()))\n",
    "    \n",
    "    print(\"Epoch {}: Avg Loss/Batch {:<20,.6f}\".format(i, np.mean(loss)))\n",
    "    model.eval()\n",
    "    evaluate_model(dataset.test_data, dataset.item_users_list, config.max_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T13:15:50.416143Z",
     "start_time": "2019-07-11T13:15:50.412316Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@1           0.397406      NDCG@1         0.397406\n",
      "HR@2           0.561881      NDCG@2         0.501178\n",
      "HR@3           0.656638      NDCG@3         0.548557\n",
      "HR@4           0.720411      NDCG@4         0.576022\n",
      "HR@5           0.767790      NDCG@5         0.594351\n",
      "HR@6           0.803819      NDCG@6         0.607185\n",
      "HR@7           0.829760      NDCG@7         0.615832\n",
      "HR@8           0.850477      NDCG@8         0.622367\n",
      "HR@9           0.865790      NDCG@9         0.626977\n",
      "HR@10          0.880022      NDCG@10        0.631091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%capture final_eval_output\n",
    "\n",
    "EVAL_AT = range(1, 11)\n",
    "hrs, ndcgs = [], []\n",
    "s = \"\"\n",
    "scores, out = get_model_scores(dataset.test_data, dataset.item_users_list, config.max_neighbors, True)\n",
    "\n",
    "for k in EVAL_AT:\n",
    "    hr, ndcg = get_eval(scores, len(scores[0])-1, k)\n",
    "    hrs.append(hr)\n",
    "    ndcgs.append(ndcg)\n",
    "    s += \"{:<14} {:<14.6f}{:<14} {:.6f}\\n\".format('HR@%s' % k, hr,\n",
    "                                                  'NDCG@%s' % k, ndcg)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:28:23.860007Z",
     "start_time": "2019-07-11T12:28:23.853778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving training log...\n"
     ]
    }
   ],
   "source": [
    "print('Saving training log...')\n",
    "with open(\"{}{}\".format(config.logdir, config.version+'.log'), 'w') as fout:\n",
    "    header = ','.join([str(k) for k in EVAL_AT])\n",
    "    fout.write(\"{},{}\\n\".format('metric', header))\n",
    "    ndcg = ','.join([str(x) for x in ndcgs])\n",
    "    hr = ','.join([str(x) for x in hrs])\n",
    "    fout.write(\"ndcg,{}\\n\".format(ndcg))\n",
    "    fout.write(\"hr,{}\".format(hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:29:23.176636Z",
     "start_time": "2019-07-11T12:29:23.166363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "# save model weights\n",
    "print(\"Saving model...\")\n",
    "torch.save(model.state_dict(), config.ssdir+config.version+'.ss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
